{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3f0a8d6-ce15-4814-a906-6c3ec061a0ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 2. Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa648ace-8882-41fa-bf2d-cede8dce8c7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Silver class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b3a04b5-3b25-4a1b-b6ac-281e20c12d17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "# Pakettien importtaus\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "class Silver():\n",
    "    def __init__(self, silver_catalog, bronze_catalog, schema):\n",
    "        '''Defining catalogs & schema.'''\n",
    "        self.silver_catalog = silver_catalog\n",
    "        self.bronze_catalog = bronze_catalog \n",
    "        self.schema = schema\n",
    "\n",
    "    def assert_missing(self, df):\n",
    "        # Check no missing values\n",
    "        print(\"Asserting no missing values...\")\n",
    "        for col in df.columns:\n",
    "            miss = df.filter(F.col(col).isNull()).count()\n",
    "            assert miss == 0, print(f\"Column {col} has missing values!\")\n",
    "        return df\n",
    "    \n",
    "    def print_dtypes(self, old_df, new_df):\n",
    "        # Print changes in data types\n",
    "        for i in range(len(old_df.dtypes)):\n",
    "            var, old_type = old_df.dtypes[i]\n",
    "            new_type = new_df.dtypes[i][1]\n",
    "            if old_type != new_type:\n",
    "                print(f\"The type of {var} was changed: {old_type} > {new_type}.\")\n",
    "            else:\n",
    "                print(f\"The type of {var} was not changed: {old_type}.\")\n",
    "\n",
    "    def clean_and_save_visits(self):\n",
    "        # Read data from bronze layer\n",
    "        dataset_name = \"visits\"\n",
    "        visits = spark.table(f\"{self.bronze_catalog}.{self.schema}.{dataset_name}_{self.bronze_catalog}\")\n",
    "\n",
    "        # display(visits.head(2))\n",
    "        print(\"Cleaning data...\")\n",
    "        visits_clean = (visits\n",
    "              .dropDuplicates() # Drop duplicates\n",
    "              .withColumn(\"Aika\", F.expr(\"try_cast(Aika as int)\")) # Cast column types\n",
    "              .withColumn(\"val\", F.expr(\"try_cast(val as int)\"))\n",
    "              .filter(F.col(\"val\").isNotNull()) # Filter out rows where \"val\" is missing\n",
    "              .withColumnRenamed('val', 'Käyntimäärä') # Rename columns\n",
    "              .withColumnRenamed('Aika', 'Vuosi')\n",
    "        )\n",
    "        self.print_dtypes(visits, visits_clean)\n",
    "        self.assert_missing(visits_clean)\n",
    "\n",
    "        print(\"Saving data...\")\n",
    "        visits_clean.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{self.silver_catalog}.{self.schema}.{dataset_name}_{self.silver_catalog}\")\n",
    "\n",
    "    def clean_and_save_customers(self):\n",
    "        dataset_name = \"customers\"\n",
    "        # Read data from bronze layer\n",
    "        customers = spark.table(f\"{self.bronze_catalog}.{self.schema}.{dataset_name}_{self.bronze_catalog}\")\n",
    "\n",
    "        # display(customers.head(2))\n",
    "        print(\"Cleaning data...\")\n",
    "        customers_clean = (customers\n",
    "              .dropDuplicates() # Drop duplicates\n",
    "              .withColumn(\"Aika\", F.expr(\"try_cast(Aika as int)\")) # Cast column types\n",
    "              .withColumn(\"val\", F.expr(\"try_cast(val as int)\"))\n",
    "              .filter(F.col(\"val\").isNotNull()) # Filter out rows where \"val\" is missing\n",
    "              .withColumnRenamed('val', 'Asiakasmäärä') # Rename columns\n",
    "              .withColumnRenamed('Aika', 'Vuosi')\n",
    "        )\n",
    "        self.print_dtypes(customers, customers_clean)\n",
    "        self.assert_missing(customers_clean)\n",
    "\n",
    "        print(\"Saving data...\")\n",
    "        customers_clean.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{self.silver_catalog}.{self.schema}.{dataset_name}_{self.silver_catalog}\")\n",
    "\n",
    "    def clean_and_save_visits_customers(self):\n",
    "        dataset_name = \"visits_customers\"\n",
    "        # Read data from bronze layer\n",
    "        visits_customers = spark.table(f\"{self.bronze_catalog}.{self.schema}.{dataset_name}_{self.bronze_catalog}\")\n",
    "\n",
    "        # display(visits_customers.head(2))\n",
    "        print(\"Cleaning data...\")\n",
    "        visits_customers_clean = (visits_customers\n",
    "              .dropDuplicates() # Drop duplicates\n",
    "              .withColumn(\"Aika\", F.expr(\"try_cast(Aika as int)\")) # Cast column types\n",
    "              .withColumn(\"val\", F.expr(\"try_cast(val as float)\"))\n",
    "              .filter(F.col(\"val\").isNotNull()) # Filter out rows where \"val\" is missing\n",
    "              .withColumnRenamed('val', 'Käynnit_per_asiakas') # Rename columns\n",
    "              .withColumnRenamed('Aika', 'Vuosi')\n",
    "        )\n",
    "        self.print_dtypes(visits_customers, visits_customers_clean)\n",
    "        self.assert_missing(visits_customers_clean)\n",
    "\n",
    "        print(\"Saving data...\")\n",
    "        visits_customers_clean.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{self.silver_catalog}.{self.schema}.{dataset_name}_{self.silver_catalog}\")\n",
    "\n",
    "    def execute_silver_pipeline(self):\n",
    "        print(\"Processing dataset Visits...\")\n",
    "        self.clean_and_save_visits()\n",
    "        print(\"Done!\")\n",
    "        print(\"Processing dataset Customers...\")\n",
    "        self.clean_and_save_customers()\n",
    "        print(\"Done!\")\n",
    "        print(\"Processing dataset Visits per Customer...\")\n",
    "        self.clean_and_save_visits_customers() \n",
    "        print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d59d7042-22da-412a-b8b7-39cd850cc3a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Transform & clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f72f474-8676-4eb8-956a-4f032490f118",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "silver = Silver(\"silver\", \"bronze\", \"avohilmo\")\n",
    "silver.execute_silver_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4bfbca6e-faf7-4c85-8b4a-e6ebd74d6301",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
